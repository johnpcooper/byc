{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time lapse imaging analysis with `byc`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install  [`byc`](https://github.com/johnpcooper/byc) and [`imagejpc`](https://github.com/johnpcooper/imagejpc) libraries to set up your environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install and configure `byc`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Clone `byc` from repo into your projects directory:\n",
    "    ```sh\n",
    "    cd c:/Users/usrname/Projects\n",
    "    git clone https://github.com/johnpcooper/byc.git\n",
    "    ```\n",
    "1. Create a python virtual environment, install required packages, and install byc\n",
    "    ```sh\n",
    "    # Install a virtual env manager\n",
    "    pip install virtualenv\n",
    "    # Create a directory for virual environments\n",
    "    cd c/Users/usrname/Projects\n",
    "    mkdir envs\n",
    "    cd envs\n",
    "    # Create the the virtual environment for byc\n",
    "    python -m venv .byc\n",
    "    # Activate the .byc virtual environment\n",
    "    .byc/Scripts/activate # windows\n",
    "    source .byc/bin/activate # macOS/linux\n",
    "    # Install python packages required to run byc in your\n",
    "    # .byc environment\n",
    "    cd c/Users/usrname/Projects/byc\n",
    "    # This may take a few minutes\n",
    "    pip install -r requirements_minimal.txt\n",
    "    # Add currently active .byc environment to the list\n",
    "    # of environments accessible in ipykernels ( like jupyter\n",
    "    # notebooks)\n",
    "    python -m ipykernel install --user --name=.byc\n",
    "    # Install the byc library in your currently active \n",
    "    # .byc environment using pip\n",
    "    cd c/Users/usrname/Projects/byc\n",
    "    pip install .\n",
    "    # Or install the byc using virtual environment wrapper\n",
    "    pip install virtualenvwrapper-win # windows\n",
    "    pip install virtualenvwrapper # macOS/linux\n",
    "    # Before running virtualenvwrapper CLI tools in your unix system,\n",
    "    # you'll need to add some paths to your .bash_profile/.bashrc\n",
    "    # See the docs here: https://virtualenvwrapper.readthedocs.io/en/latest/install.html\n",
    "    # Add the byc source directory to the list of source paths\n",
    "    # virtualenvwrapper will look for packages to import\n",
    "    add2virtualenv .\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install and configure `imagejpc`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download [fiji](https://imagej.net/software/fiji/downloads). If you're on windows, extract files and move `fiji.app` folder to your appdata directory (e.g. `c/Users/usrname/AppData/Local`). If you're on macOS, leave the downloaded Fiji shortcut wherever its convenient and access plugins folder etc. byc '^ctrl' + 'left click' on the Fiji shortcut and select 'Show package contents' \n",
    "1. Clone `imagejpc` into your projects directory:\n",
    "    ```sh\n",
    "    cd c/Users/usrname/Projects/\n",
    "    git clone https://github.com/johnpcooper/imagejpc\n",
    "    ``` \n",
    "1. Edit hardcoded script location references in `macros/addCell.ijm`. Change the values that `script` and `python` are set to to reflect your local `byc` and `.byc` environment paths\n",
    "1. Copy all plugin files (`.py` and `.ijm`) from `imagejpc/utilities` and `imagejpc/macros` into the plugins folder of Fiji at `C:/Users/usrname/AppData/Local`\n",
    "1. Copy `imagejpc/macros/addCell.ijm` to your Fiji installation macros folder at `C:/Users/usrname/AppData/Local/Fiji.app/macros` (so that `IJ.runMacroFile('addCell.ijm', arg)` will be able to find it when run from a plugin)\n",
    "1. Run Fiji with the executable at `C:/Users/usrname/AppData/Local/Fiji.app/ImageJ-win64.exe`. Fiji will automatically find the files you added to its plugins folder above and install them\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register timelapse imaging output from &micro;manager"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. If you don't have a dataset to analyze, an example dataset from this [box link](https://utexas.box.com/s/tzfxumwhate722d4n3x8k273p65xuh9v)\n",
    "1. Run the `byc` alignment script on raw &micro;manager output\n",
    "    ```sh\n",
    "    # activate your .byc environment\n",
    "    cd C:/Users/usrname/Projects\n",
    "    envs/.byc/Scripts/activate\n",
    "    # Run the alignment script. Once run, a GUI window will ask you\n",
    "    # to choose the directory holding data. In the example dataset,\n",
    "    # this is 20230126_byc_1\n",
    "    python byc/bin/align_byc_expt.py # this will take a few minutes per xy position\n",
    "    ```\n",
    "1. The above aligned channel stacks are saved in a folder called `output`. You'll now want to copy these stacks into your data directory as detailed below before starting to annotate the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotate raw data with cell location and bud/cell fission events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create experiment and compartment directories and add channel stacks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  Add a byc data directory to your `byc` installation location. This is where `byc` modules look for data during annotation and following analysis steps. If you installed `byc` using `add2virtualenv` above, the data directory that comes with the repo is already in the \"installation location\" and no new data directory needs to be created\n",
    "    ```sh\n",
    "    mkdir C:/Users/usrname/Projects/envs/.byc/Lib/site-packages/data\n",
    "    # if you used add2virtualenv, the data directory will already be at \n",
    "    # C:/Users/usrname/Projects/byc/data\n",
    "    ```\n",
    "1. Create an experiment directory in the byc data directory created above\n",
    "    ```sh\n",
    "    mkdir C:/Users/usrname/Projects/envs/.byc/Lib/site-packages/data/data/20230126_byc\n",
    "    # or if you used add2virtualenv\n",
    "    mkdir C:/Users/usrname/Projects/byc/data/20230126_byc\n",
    "    # 20230126_byc is the experiment name in the example dataset\n",
    "    ```\n",
    "1. Create a compartment directory in the experiment directory created above. This will hold all channel stacks corresponding to xy positions collected in the experiment that are within a certain flow compartment of the microfluidic device. The name of the compartment directory needs to identify the strain being imaged and potentially other conditions like small molecule concentration etc.\n",
    "    ```sh\n",
    "    # This compartment directory name typically includes the strain number\n",
    "    # and any other information necessary for describing the strain and \n",
    "    # conditions of cells in this compartment\n",
    "    mkdir C:/Users/usrname/Projects/envs/.byc/Lib/site-packages/data/20230126_byc/20230126_byc_JPC228_UBL-YFP-Su9_BY4741\n",
    "    # Or if you used add2virtualenv\n",
    "    mkdir C:/Users/usrname/Projects/byc/data/20230126_byc/20230126_byc_JPC228_UBL-YFP-Su9_BY4741\n",
    "    ```\n",
    "1. Copy the channel stacks from `output` to the appropriate compartment directory (`20230126_byc_JPC228_UBL-YFP-Su9_BY4741` in the example)\n",
    "1. You are now ready start annotating data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotate cell location (crop ROIs) and budding events (bud ROIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Run Fiji (`C:/Users/usrname/AppData/Local/Fiji.app/ImageJ-win64.exe`)\n",
    "1. Open the xy stack you want to analyze (`20230126_byc\\20230126_byc_JPC228_UBL-YFP-Su9_BY4741\\20230126_byc_xy09_bf_stack.tif` inside the byc data directory you created above)\n",
    "1. For each cell you want to analyze:\n",
    "    1. Annotate crop ROIs, which are essentially key frames, to track the cell of interest. \n",
    "        * Draw a rectangular box with its center somewhere inside the cell at the first frame you want to segment. Press 't' to add this box selection to `RoiManager`. \n",
    "        * Scroll through the stack until you need to adjust the box selection to keep its center within the cell of interest. When needed, move the box so its center is within the cell of interest and press 't' to add the box to `RoiManager`\n",
    "        * Add another ROI like above at the last frame you want to segment\n",
    "        * Make sure that your ROIs in `RoiManager` are sorted by position (select all ROIs, right click, click 'sort')\n",
    "        * Press 'L' to focus the Fiji search bar and type 'save cell roi set` and press enter\n",
    "        * When prompted, enter ROI set type as \"crop\". Enter other annotation information as relevant\n",
    "    1. Annotate bud ROIs, which are rectangular selections marking the frame before a bud first becomes visible (for cerevisiae data) or the frame at which the vertical fission line first becomes visible (for pombe data). These frame of interest are referred to as the \"bud frame\":\n",
    "        * For each bud frame (as described above) draw a rectangular box around the area where the budding or fission event occurs. If analyzing budding yeast data, this frame will be used to annotate the shape of the daughter cell that came before the daughter appearing at the bud frame. If the previous daughter was round, press \"6\" to add the bud frame ROI to `RoiManager`. If the previous daughter was elongated, press \"7\" to add the bud frame ROI to `RoiManager`. If you're annotating fission yeast or daughter isn't relevant, simply press 't' to add an unlablled bud ROI to `RoiManager`\n",
    "        * Once you have created an ROI for each bud frame as described above, add one more frame annotating the end of our observation of the current cell. If the cell escapes or dies, create an ROI at the frame in which the cell was last seen alive/in its catch tube. If the cells is still alive in the device when the experiment ends, create an ROI at the last frame of the stack\n",
    "        * Sort the ROIs in `RoiManager`, press 'L' to focus the search bar, and enter 'save cell roi set'\n",
    "        * When prompted, enter 'bud' as ROI set type. For 'end_event_type', enter 'death' if the cell dies during data collection, enter 'escape' if the cell escaped before dying or the end of the experiment, or enter 'sen' if the cell was still alive at the end of the experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment cells and measure fluorescence using annotation data created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "\n",
    "from byc import constants, files, database, segmentation, utilities, trace_tools\n",
    "from byc import standard_analysis as sa\n",
    "from byc import plotting\n",
    "from byc import fitting_tools as ft\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "for mod in [\n",
    "    constants,\n",
    "    files,\n",
    "    database,\n",
    "    segmentation,\n",
    "    utilities,\n",
    "    trace_tools\n",
    "]:\n",
    "    reload(mod)\n",
    "plotting.set_styles(plt, matplotlib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the experiment and compartment you want to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compartmentname = \"20230201_byc_JPC226-20230127-int_UBL-YFP-Su9x3_rpn4d\"\n",
    "channels = \"bf yfp rfp\"\n",
    "collection_interval_minutes = 10\n",
    "channels_list = channels.split()\n",
    "exptname = utilities.exptname_from_compartment(compartmentname)\n",
    "compartmentdir = files.get_byc_compartmentdir(exptname, compartmentname)\n",
    "# Check that there are crop and bud roi dfs, which contain\n",
    "# annotated information about the .zip roi files, for all the cells in the dataset\n",
    "utilities.check_bud_and_crop_roi_dfs(compartmentdir)\n",
    "mdf = utilities.generate_mdf(exptname, compartmentname, channels=channels_list)\n",
    "filename = f'{compartmentname}_alldf_measured.csv.gzip'\n",
    "allmeasuredpath = os.path.join(compartmentdir, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment cell areas with fluorescence data using otsu thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segment dataset de novo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = utilities.generate_mdf(exptname, compartmentname, channels=channels_list)\n",
    "# Create cell crop stack files\n",
    "segmentation.write_cell_crop_stacks(mdf, return_cellstacks_dict=False)\n",
    "segkwargs = {\n",
    "    'collection_interval_minutes': 10,\n",
    "    'maskpath_suffix': 'nucleus',\n",
    "    'channel_to_segment': 'gfp',\n",
    "    'channels_to_measure': ['gfp'],\n",
    "    'var_to_exclude_rois': 'major_axis_length',\n",
    "    'set_outliers_to_nan': True\n",
    "}\n",
    "celldfs = segmentation.segment_and_measure_byc_dataset(mdf[0:5], **segkwargs)\n",
    "# Further processing and annotation of fluorescence traces\n",
    "# Includes features like cell cycle duration and number of cell divisions before death\n",
    "segmentation.refine_and_annotate_celldfs(celldfs, mdf,\n",
    "    collection_interval_minutes=10,\n",
    "    channels_to_normalize=['gfp'],\n",
    "    yvars=['mean'],\n",
    "    channel_auto_fluors=[155]\n",
    "    )\n",
    "tracesavepath = os.path.join(mdf.loc[0, 'compartment_dir'], f'{exptname}_alldf.csv')\n",
    "alldf = pd.concat(celldfs)\n",
    "alldf.index = range(len(alldf))\n",
    "alldf.to_csv(tracesavepath, index=False)\n",
    "print(f'Saved traces df at\\n{tracesavepath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in existing segmented data measurents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracesavepath = os.path.join(mdf.loc[0, 'compartment_dir'], f'{exptname}_alldf.csv')\n",
    "alldf = pd.read_csv(tracesavepath)\n",
    "print(f'Read in traces df from\\n{tracesavepath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of individual fluorescence traces over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 3))\n",
    "fig.set_dpi(300)\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "linekwargs = {\n",
    "    'y': 'yfp_mean',\n",
    "    'x': 'hours',\n",
    "    'hue': 'cell_index',\n",
    "    'data': alldf,\n",
    "    'ax': ax1,\n",
    "    'palette': 'rainbow'\n",
    "}\n",
    "\n",
    "sns.lineplot(**linekwargs)\n",
    "\n",
    "linekwargs = {\n",
    "    'y': 'rfp_mean',\n",
    "    'x': 'hours',\n",
    "    'hue': 'cell_index',\n",
    "    'data': alldf,\n",
    "    'ax': ax2,\n",
    "    'palette': 'rainbow'\n",
    "}\n",
    "\n",
    "sns.lineplot(**linekwargs)\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.set_xlim(0, 5)\n",
    "    plotting.remove_spines(ax)\n",
    "    plotting.format_ticks(ax)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segment cell areas with brightfield data using a radial intensity peak-based segmentation method implemented in the `byc` script `segment_byc_dataset`\n",
    "\n",
    "Usually this is done in budding yeast datasets where we are measuring dynamics of a fluorescent signal and don't have a fluorophore we can use for segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_path = os.path.join(constants.source_path, 'bin/segment_byc_dataset.py')\n",
    "%run $script_path $compartmentname \"bf yfp rfp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the measurements dataframe created using the script above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = utilities.generate_mdf(exptname, compartmentname)\n",
    "celltracedfs = segmentation.get_cell_trace_dfs_from_outline_vertices(\n",
    "    mdf,\n",
    "    collection_interval_minutes=collection_interval_minutes\n",
    ")\n",
    "filename = f'{exptname}_alldf.csv'\n",
    "tracesavepath = os.path.join(compartmentdir, filename)\n",
    "traces_df = pd.concat(celltracedfs, ignore_index=True)\n",
    "traces_df.to_csv(tracesavepath, index=False)\n",
    "print(f'Saved all cell traces df at\\n{tracesavepath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x='hours', y='yfp_mean', data=traces_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in table of on record per frame per cell and annotate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f'{exptname}_alldf.csv'\n",
    "tracesavepath = os.path.join(compartmentdir, filename)\n",
    "table = pd.read_csv(tracesavepath)\n",
    "# Necessary for backwards compatibility\n",
    "for channel in ['rfp', 'yfp']:\n",
    "    legacy_name = f'Mean_{channel}_auto'\n",
    "    new_name = f'{channel}_mean'\n",
    "    if legacy_name in table.columns:\n",
    "        print(f'Found legacy named column {legacy_name}')\n",
    "        print(f'Renaming to {new_name}')\n",
    "        table.loc[:, new_name] = table.loc[:, legacy_name]\n",
    "# Annotate all information found in the master index dataframe\n",
    "# into the compartment table\n",
    "for col in mdf.columns:\n",
    "    if col not in table.columns:\n",
    "        for cell_index in mdf.cell_index.unique():\n",
    "            val = mdf.loc[cell_index, col]\n",
    "            table.loc[table.cell_index==cell_index, col] = val\n",
    "table.loc[:, 'hours_rel'] = table.frame*(10/60)\n",
    "table.loc[:, 'frame_number'] = table.frame\n",
    "table.loc[:, 'exptname'] = exptname\n",
    "celldfs = [table[table.cell_index==i] for i in table.cell_index.unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in celldfs:\n",
    "    df.loc[:, 'compartment_reldir'] = mdf.compartment_reldir.iloc[0]\n",
    "segmentation.refine_and_annotate_celldfs(celldfs, mdf,\n",
    "    collection_interval_minutes=10,\n",
    "    channels_to_normalize=['rfp', 'yfp'],\n",
    "    yvars=['mean'],\n",
    "    channel_auto_fluors=[117, 136]\n",
    "    )\n",
    "\n",
    "alldf = pd.concat(celldfs)\n",
    "alldf.index = range(len(alldf))\n",
    "alldf.to_csv(tracesavepath, index=False)\n",
    "print(f'Saved traces df at\\n{tracesavepath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scan chase fit start frames to find an average t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldf.first_crop_frame.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_crop_frame = 9\n",
    "\n",
    "kwargs = {\n",
    "    'xmin': 4,\n",
    "    'xmax': 24\n",
    "}\n",
    "\n",
    "scandfs = []\n",
    "for tracedf in celldfs:\n",
    "    if tracedf.first_crop_frame.iloc[0] == first_crop_frame:\n",
    "        print(f'Scanning fit start frames for cell {tracedf.cell_index.iloc[0]}')\n",
    "\n",
    "        scandf = ft.scan_start_frames(tracedf,\n",
    "                                      col_name='yfp_mean',\n",
    "                                      xvar='frame',\n",
    "                                      **kwargs)\n",
    "        scandfs.append(scandf)\n",
    "allscandf = pd.concat(scandfs, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allscandf.index = range(len(allscandf))\n",
    "scandf = allscandf\n",
    "yvar = 'b'\n",
    "ylabel = 'Rate constant'\n",
    "fig = plt.figure(figsize=(5, 2)) \n",
    "fig.set_dpi(300)\n",
    "xlim = (0, 30)\n",
    "ylim = (-0.1, 0.5)\n",
    "size=1\n",
    "color = 'black'\n",
    "ax = fig.add_subplot(121)\n",
    "ax.set_ylim(ylim)\n",
    "ax.set_xlim(xlim)\n",
    "ax.scatter(allscandf.start_frame, allscandf[yvar], s=size, color=color, alpha=0.2)\n",
    "sns.lineplot(x='start_frame', y=yvar, data=allscandf,\n",
    "             color='black', estimator=np.median, ax=ax)\n",
    "ax.set_title(f'Chase at frame {first_crop_frame}')\n",
    "\n",
    "\n",
    "for a in [ax]:\n",
    "    a.set_ylabel(ylabel)\n",
    "    a.set_xticks(np.arange(0, np.max(xlim)+1, 5))\n",
    "    a.set_xlabel('t0 frame')    \n",
    "    \n",
    "plotting.format_ticks(ax)\n",
    "plotting.remove_spines(ax)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allscandf.index = range(len(allscandf))\n",
    "scandf = allscandf\n",
    "yvar = 'ss_residuals'\n",
    "ylabel = 'Sum Sq. Residuals'\n",
    "fig = plt.figure(figsize=(5, 2)) \n",
    "fig.set_dpi(300)\n",
    "xlim = (0, 30)\n",
    "ylim = (-0.1, 2)\n",
    "size=1\n",
    "color = 'black'\n",
    "ax = fig.add_subplot(121)\n",
    "ax.set_ylim(ylim)\n",
    "ax.set_xlim(xlim)\n",
    "ax.scatter(allscandf.start_frame, allscandf[yvar], s=size, color=color, alpha=0.2)\n",
    "sns.lineplot(x='start_frame', y=yvar, data=allscandf,\n",
    "             color='black', estimator=np.median, ax=ax)\n",
    "ax.set_title(f'Chase at frame {first_crop_frame}')\n",
    "\n",
    "\n",
    "for a in [ax]:\n",
    "    a.set_ylabel(ylabel)\n",
    "    a.set_xticks(np.arange(0, np.max(xlim)+1, 5))\n",
    "    a.set_xlabel('t0 frame')    \n",
    "    \n",
    "plotting.format_ticks(ax)\n",
    "plotting.remove_spines(ax)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_crop_frame = 144\n",
    "\n",
    "kwargs = {\n",
    "    'xmin': 4,\n",
    "    'xmax': 24\n",
    "}\n",
    "\n",
    "scandfs = []\n",
    "for tracedf in celldfs:\n",
    "    if tracedf.first_crop_frame.iloc[0] == first_crop_frame:\n",
    "        print(f'Scanning fit start frames for cell {tracedf.cell_index.iloc[0]}')\n",
    "\n",
    "        scandf = ft.scan_start_frames(tracedf,\n",
    "                                      col_name='yfp_mean',\n",
    "                                      xvar='frame',\n",
    "                                      **kwargs)\n",
    "        scandfs.append(scandf)\n",
    "allscandf = pd.concat(scandfs, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allscandf.index = range(len(allscandf))\n",
    "scandf = allscandf\n",
    "yvar = 'b'\n",
    "ylabel = 'Rate constant'\n",
    "fig = plt.figure(figsize=(5, 2)) \n",
    "fig.set_dpi(300)\n",
    "xlim = (0, 30)\n",
    "ylim = (-0.1, 0.5)\n",
    "size=1\n",
    "color = 'black'\n",
    "ax = fig.add_subplot(121)\n",
    "ax.set_ylim(ylim)\n",
    "ax.set_xlim(xlim)\n",
    "ax.scatter(allscandf.start_frame, allscandf[yvar], s=size, color=color, alpha=0.2)\n",
    "sns.lineplot(x='start_frame', y=yvar, data=allscandf,\n",
    "             color='black', estimator=np.median, ax=ax)\n",
    "ax.set_title(f'Chase at frame {first_crop_frame}')\n",
    "\n",
    "\n",
    "for a in [ax]:\n",
    "    a.set_ylabel(ylabel)\n",
    "    a.set_xticks(np.arange(0, np.max(xlim)+1, 5))\n",
    "    a.set_xlabel('t0 frame')    \n",
    "    \n",
    "plotting.format_ticks(ax)\n",
    "plotting.remove_spines(ax)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allscandf.index = range(len(allscandf))\n",
    "scandf = allscandf\n",
    "yvar = 'ss_residuals'\n",
    "ylabel = 'Sum Sq. Residuals'\n",
    "fig = plt.figure(figsize=(5, 2)) \n",
    "fig.set_dpi(300)\n",
    "xlim = (0, 30)\n",
    "ylim = (-0.1, 2)\n",
    "size=1\n",
    "color = 'black'\n",
    "ax = fig.add_subplot(121)\n",
    "ax.set_ylim(ylim)\n",
    "ax.set_xlim(xlim)\n",
    "ax.scatter(allscandf.start_frame, allscandf[yvar], s=size, color=color, alpha=0.2)\n",
    "sns.lineplot(x='start_frame', y=yvar, data=allscandf,\n",
    "             color='black', estimator=np.median, ax=ax)\n",
    "ax.set_title(f'Chase at frame {first_crop_frame}')\n",
    "\n",
    "\n",
    "for a in [ax]:\n",
    "    a.set_ylabel(ylabel)\n",
    "    a.set_xticks(np.arange(0, np.max(xlim)+1, 5))\n",
    "    a.set_xlabel('t0 frame')    \n",
    "    \n",
    "plotting.format_ticks(ax)\n",
    "plotting.remove_spines(ax)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check on all the unique crop starts in the data set incase \n",
    "# there were some other than the two above\n",
    "tracesdf = pd.concat(celldfs, sort=False)\n",
    "\n",
    "crop_starts = np.sort(list(tracesdf.first_crop_frame.unique()))\n",
    "crop_starts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot t0 normalized substrate fluorescence over time for each cell using the t0 chase frames defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_starts = np.sort(list(tracesdf.first_crop_frame.unique()))\n",
    "chase_frames = [22, 13, 12]\n",
    "\n",
    "chase_frame_dict = dict(zip(list(crop_starts), chase_frames))\n",
    "\n",
    "table = tracesdf\n",
    "yvar = 'yfp_mean'\n",
    "nrows = 1\n",
    "ncols = len(crop_starts)\n",
    "height = nrows*2.5\n",
    "width = ncols*2.5\n",
    "xlim = (0, 3)\n",
    "ylim = (0, 1.2)\n",
    "delta_t = 10\n",
    "fig = plt.figure(figsize=(width, height))\n",
    "fig.set_dpi(300)\n",
    "axes = [fig.add_subplot(nrows, ncols, i+1) for i in range(len(crop_starts))]\n",
    "axdict = dict(zip(crop_starts, axes))\n",
    "# Plot each individual cell from each chase\n",
    "for crop_start in crop_starts:\n",
    "    ax = axdict[crop_start]\n",
    "    ax.set_ylim(ylim)\n",
    "    ax.set_xlim(xlim)\n",
    "    chase_frame = chase_frame_dict[crop_start]\n",
    "    xy = (np.max(xlim)*0.4, np.max(ylim)*0.8)\n",
    "    xy2 = (xy[0], np.max(ylim)*0.7)\n",
    "    chase_hours = ((crop_start+chase_frame)*delta_t)/60\n",
    "    chase_hours = np.round(chase_hours, 3)\n",
    "    ax.annotate(f'Chase at {chase_hours} hrs', xy=xy)\n",
    "    ax.annotate(f'Chase frame={chase_frame}', xy=xy2)\n",
    "    startdf = table[table.first_crop_frame==crop_start]\n",
    "    for cell_index in startdf.cell_index.unique():\n",
    "        \n",
    "        df = startdf[startdf.cell_index==cell_index]\n",
    "        df.sort_values(by='frame', inplace=True)\n",
    "        x = df.frame[chase_frame:] - chase_frame\n",
    "        x = (x*delta_t)/60\n",
    "        y = df[yvar][chase_frame:] - df[yvar][:].min()\n",
    "        y = y/y.iloc[0]\n",
    "        ax.plot(x, y)\n",
    "        ax.set_ylabel('YFP(t)/YFP(t0)')\n",
    "        ax.set_xlabel('Time after chase (hrs)')\n",
    "        plotting.remove_spines(ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relabel tracedfs after having determined chase starts above\n",
    "channels = ['bf', 'yfp']\n",
    "args = [exptname,\n",
    "        compartmentname]\n",
    "kwargs = {'age_state': 'old',\n",
    "          'chase_frame_dict': chase_frame_dict}\n",
    "\n",
    "mdf = sa.create_and_annotate_mdf(*args, **kwargs)\n",
    "# Set chase frames in celldf table according to above\n",
    "crop_starts = chase_frame_dict.keys()\n",
    "# For some reason dist_from_sen is getting fucked up so redefine\n",
    "# it straight from master index df\n",
    "for cell_index in mdf.cell_index.unique():\n",
    "    abs_chase_frame = mdf[mdf.cell_index==cell_index].abs_chase_frame.iloc[0]\n",
    "    dist_from_sen = mdf[mdf.cell_index==cell_index].dist_from_sen.iloc[0]\n",
    "    table.loc[table.cell_index==cell_index, 'dist_from_sen'] = dist_from_sen\n",
    "    table.loc[table.cell_index==cell_index, 'abs_chase_frame'] = abs_chase_frame\n",
    "\n",
    "for crop_start in crop_starts:\n",
    "    chase_frame = chase_frame_dict[crop_start]\n",
    "    table.loc[table.first_crop_frame==crop_start, 'chase_frame'] = chase_frame\n",
    "# Add a t0 normalized column to each trace dataframe\n",
    "tracedfs = [table[table.cell_index==cidx] for cidx in table.cell_index.unique()]\n",
    "for df in tracedfs:\n",
    "    df.index = range(len(df))\n",
    "tracedfs = [sa.t0_normalize_trace_df(tracedf,\n",
    "                                     yvar='yfp_mean',\n",
    "                                     norm_col_name='yfp_norm') for tracedf in tracedfs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot t0 normalized traces with color corresponding to senescence proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette(\"Spectral\", n_colors=int(np.max(table.dist_from_sen))+1)\n",
    "\n",
    "fig, ax = plotting.figure_ax(width_scale=1, height_scale=0.1)\n",
    "ax.set_xlim(0, 27)\n",
    "ax.set_xticks([0, 5, 10, 15, 20, 25])\n",
    "ax.get_yaxis().set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "plot = sns.palplot(palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = tracedfs\n",
    "savefig=True\n",
    "y_var = 'yfp_norm'\n",
    "plotkwargs = {'alpha': 0.6,\n",
    "              'linewidth': 1.5}\n",
    "\n",
    "ylabel = 'YFP(t)/YFP(t0)'\n",
    "xlabel = 'Time after chase (hrs)'\n",
    "compdir = os.path.join(constants.byc_data_dir, mdf.compartment_reldir.unique()[0])\n",
    "exptdir = os.path.abspath(os.path.join(compdir, '..'))\n",
    "filetype = '.png'\n",
    "savepath = os.path.join(compdir, f'Yfp_vs_time_color_dist_from_sen{filetype}')\n",
    "\n",
    "ylim = (0, 1.2)\n",
    "xlim = (0, 3)\n",
    "fig = plt.figure(figsize=(2.5, 2.5))\n",
    "fig.set_dpi(300)\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim(xlim)\n",
    "ax.set_ylim(ylim)\n",
    "\n",
    "colors = sns.color_palette('husl', len(dfs))\n",
    "for i, df in enumerate(dfs):\n",
    "    chase_frame = df.chase_frame.unique()[0]\n",
    "    y = df.loc[chase_frame:, y_var]\n",
    "    x = [(i*10)/60 for i in range(len(y))]\n",
    "    dist_from_sen = df.dist_from_sen.iloc[0]\n",
    "    if not np.isnan(dist_from_sen):\n",
    "        color =palette[int(dist_from_sen)]\n",
    "        ax.plot(x, y, color=color, label=f'Cell {i}', **plotkwargs)\n",
    "    else:\n",
    "        print(f'Dist from sen is nan for cell {df.cell_index.unique()[0]}')\n",
    "\n",
    "# ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "for spine in [ax.spines[key] for key in ['top', 'right']]:\n",
    "    spine.set_visible(False)\n",
    "    \n",
    "ax.set_ylabel(ylabel, fontsize=14)\n",
    "ax.set_xlabel(xlabel, fontsize=14)\n",
    "loc = (0.3*np.max(xlim), 0.9*np.max(ylim))\n",
    "# ax.annotate(f'Chase frame = {chase_frame}', xy=loc)\n",
    "plotting.format_ticks(ax, xminorspace=0.2, yminorspace=0.1)\n",
    "plt.tight_layout()\n",
    "if savefig:\n",
    "    fig.savefig(savepath)\n",
    "    print(f'Saved figure at:\\n{savepath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit fluorescence traces to exponential decay to derive pseudo first order rate constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = 'yfp_mean'\n",
    "fits_df = ft.get_all_fits_df(tracedfs, None, 18, col_name=col_name)\n",
    "# Get rid of failed fit data\n",
    "fits_df = fits_df[fits_df.b.isna() == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each cell, scatter plot fluorescence vs time after chase and line plot the fit so they can be visually inspected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'all_cell_fits.svg'\n",
    "compdir = os.path.join(constants.byc_data_dir, mdf.compartment_reldir.iloc[0])\n",
    "savepath = os.path.join(compdir, filename)\n",
    "\n",
    "fits_df.sort_values(by='cell_index', inplace=True)\n",
    "nrows = 37\n",
    "ncols = 6\n",
    "fig = plt.figure(figsize=(ncols*2.4, nrows*2.4))\n",
    "fig.set_dpi(300)\n",
    "i=1\n",
    "xlim = (0, 3)\n",
    "ylim = (0, 1.2)\n",
    "for cell_index in fits_df.cell_index.unique():\n",
    "    df = fits_df[fits_df.cell_index==cell_index]\n",
    "    dist_from_sen = df.dist_from_sen.unique()[0]\n",
    "    rate = np.round(df.b.unique()[0], 3)\n",
    "    ax = fig.add_subplot(nrows, ncols, i)\n",
    "    sns.scatterplot(x='x_input', y='y_input_norm', color='black',\n",
    "                    data=df, ax=ax)\n",
    "    sns.lineplot(x='x_input', y='y_pred_norm', color='black',\n",
    "                 data=df, ax=ax)\n",
    "    \n",
    "    ax.set_title(f'Cell{cell_index}')\n",
    "   \n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "    shapiro_p = df.shapiro_p.iloc[0]\n",
    "    shapiro_p_round = np.round(shapiro_p, 3)\n",
    "    xy = (0.5, np.max(ylim)*0.8)\n",
    "    xyrate = (0.5, np.max(ylim)*0.7)\n",
    "    xyabschase = (0.5, np.max(ylim)*0.6)\n",
    "    if shapiro_p < 0.05:\n",
    "        color= 'red'\n",
    "    else:\n",
    "        color='black'\n",
    "    ax.annotate(f'Shapiro p={shapiro_p_round}', xy=xy, color=color)\n",
    "    ax.annotate(f'Rate={rate}', xy=xyrate)\n",
    "    ax.annotate(f'Abs chase frame={int(df.abs_chase_frame.iloc[0])}', xy=xyabschase)\n",
    "    i+=1\n",
    "plt.tight_layout()\n",
    "fig.savefig(savepath)\n",
    "print(f'Figure saved at\\n{savepath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_chase_frames = [tracedf.abs_chase_frame.iloc[0] for tracedf in tracedfs]\n",
    "chase_frames = [tracedf.chase_frame.iloc[0] for tracedf in tracedfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define chase offsets based on visual inspection of all cell fits plot below\n",
    "# There are often cases where an exponential decay clearly starts one timepoint\n",
    "# after the median residuals minimum calculated above\n",
    "chase_offsets = {\n",
    "    0:1,\n",
    "    1:1,\n",
    "    4:1,\n",
    "    8:2,\n",
    "    15:2,\n",
    "    17:2,\n",
    "    20:1,\n",
    "    28:1,\n",
    "    29:1,\n",
    "    32:1,\n",
    "    33:2,\n",
    "    41:1,\n",
    "    42:2,\n",
    "    45:1,\n",
    "    46:1,\n",
    "    47:1,\n",
    "    56:1,\n",
    "    59:1,\n",
    "    62:2,\n",
    "    66:1,\n",
    "    58:2,\n",
    "    69:1,\n",
    "    70:1,\n",
    "    78:1,\n",
    "    79:1,\n",
    "    81:1,\n",
    "    83:1,\n",
    "    96:1,\n",
    "    105:2,\n",
    "    113:1,\n",
    "    117:1,\n",
    "    118:1,\n",
    "    119:1,\n",
    "    120:2,\n",
    "    132:1,\n",
    "    142:1,\n",
    "    144:1\n",
    "}\n",
    "# Include cell indices where signal was clearly already at background \n",
    "# and fit is just to noise\n",
    "drops = [\n",
    "    50,\n",
    "    109,\n",
    "    115\n",
    "]\n",
    "if chase_offsets:\n",
    "    for cell_index, chase_frame_offset in chase_offsets.items():\n",
    "        tracedfs[cell_index].loc[:, 'abs_chase_frame'] = tracedfs[cell_index].loc[:, 'abs_chase_frame'] + chase_frame_offset\n",
    "        tracedfs[cell_index].loc[:, 'chase_frame'] = tracedfs[cell_index].loc[:, 'chase_frame'] + chase_frame_offset\n",
    "col_name = 'yfp_mean'\n",
    "fits_df = ft.get_all_fits_df(tracedfs, None, 18, col_name=col_name)\n",
    "# Get rid of failed fit data\n",
    "fits_df = fits_df[fits_df.b.isna() == False]\n",
    "# Drop cells that are clearly bad data based on above plots\n",
    "fits_df = fits_df[~(fits_df.cell_index.isin(drops))]\n",
    "fits_df.index = range(len(fits_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'all_cell_fits.svg'\n",
    "compdir = os.path.join(constants.byc_data_dir, mdf.compartment_reldir.iloc[0])\n",
    "savepath = os.path.join(compdir, filename)\n",
    "\n",
    "fits_df.sort_values(by='cell_index', inplace=True)\n",
    "nrows = 37\n",
    "ncols = 6\n",
    "fig = plt.figure(figsize=(ncols*2.4, nrows*2.4))\n",
    "fig.set_dpi(300)\n",
    "i=1\n",
    "xlim = (0, 3)\n",
    "ylim = (0, 1.2)\n",
    "for cell_index in fits_df.cell_index.unique():\n",
    "    df = fits_df[fits_df.cell_index==cell_index]\n",
    "    dist_from_sen = df.dist_from_sen.unique()[0]\n",
    "    rate = np.round(df.b.unique()[0], 3)\n",
    "    ax = fig.add_subplot(nrows, ncols, i)\n",
    "    sns.scatterplot(x='x_input', y='y_input_norm', color='black',\n",
    "                    data=df, ax=ax)\n",
    "    sns.lineplot(x='x_input', y='y_pred_norm', color='black',\n",
    "                 data=df, ax=ax)\n",
    "    \n",
    "    ax.set_title(f'Cell{cell_index}')\n",
    "   \n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)\n",
    "    shapiro_p = df.shapiro_p.iloc[0]\n",
    "    shapiro_p_round = np.round(shapiro_p, 3)\n",
    "    xy = (0.5, np.max(ylim)*0.8)\n",
    "    xyrate = (0.5, np.max(ylim)*0.7)\n",
    "    xyabschase = (0.5, np.max(ylim)*0.6)\n",
    "    if shapiro_p < 0.05:\n",
    "        color= 'red'\n",
    "    else:\n",
    "        color='black'\n",
    "    ax.annotate(f'Shapiro p={shapiro_p_round}', xy=xy, color=color)\n",
    "    ax.annotate(f'Rate={rate}', xy=xyrate)\n",
    "    ax.annotate(f'Abs chase frame={int(df.abs_chase_frame.iloc[0])}', xy=xyabschase)\n",
    "    i+=1\n",
    "plt.tight_layout()\n",
    "fig.savefig(savepath)\n",
    "print(f'Figure saved at\\n{savepath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any more cells that are clearly bad data based on above plots\n",
    "drops = [\n",
    "]\n",
    "fits_df = fits_df[~(fits_df.cell_index.isin(drops))]\n",
    "fits_df.index = range(len(fits_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the fits_df (fluorescence traces) and fits_table (one row per cell with its rate constant) so they can be read in to the database elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'mdf': mdf,\n",
    "          'fits_df': fits_df,\n",
    "          'drops': drops}\n",
    "fits_df, fits_table = database.write_final_fits_dfs(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter plot of exponential decay rate constants vs. number of buds that will be produced before death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fits_table\n",
    "mdf = mdf\n",
    "yvar = 'b'\n",
    "xvar = 'dist_from_sen'\n",
    "scatterkwargs = {'color': 'white',\n",
    "                 'edgecolor': 'blue'}\n",
    "linekwargs = {'color': 'blue',\n",
    "              'linestyle': '--'}\n",
    "ylabel = 'k (hr$^{-1}$)'\n",
    "xlabel = 'Generations from\\nSenescence'\n",
    "compdir = os.path.join(constants.byc_data_dir, mdf.compartment_reldir.unique()[0])\n",
    "exptdir = os.path.abspath(os.path.join(compdir, '..'))\n",
    "savepath = os.path.join(compdir, f'{yvar}_vs_{xvar}.svg')\n",
    "from scipy.stats import linregress\n",
    "ylim = (0, 6)\n",
    "xlim = (30, -1)\n",
    "xminorspace = 1\n",
    "yminorspace = 0.1\n",
    "xticks = np.linspace(xlim[0], 0, 7)\n",
    "fig = plt.figure(figsize=(2.5, 2.5))\n",
    "fig.set_dpi(300)\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim(xlim)\n",
    "ax.set_ylim(ylim)\n",
    "ax.set_xticks(xticks)\n",
    "x = df.loc[:, xvar]\n",
    "y = df.loc[:, yvar]\n",
    "ax.scatter(x, y, **scatterkwargs)\n",
    "\n",
    "# ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "for spine in [ax.spines[key] for key in ['top', 'right']]:\n",
    "    spine.set_visible(False)\n",
    "    \n",
    "ax.set_ylabel(ylabel, fontsize=12)\n",
    "ax.set_xlabel(xlabel, fontsize=12)\n",
    "\n",
    "# Plot linear regression\n",
    "slope, intercept, r, p, se = linregress(x, y)\n",
    "x_smooth = np.linspace(np.min(xlim), np.max(xlim), 30)\n",
    "y_pred = ft.line(x_smooth, slope, intercept)\n",
    "r_sq = r*r\n",
    "r_sq_term = 'R$^2$'\n",
    "r_sq_label = f'{r_sq_term}={np.round(r_sq, 3)}'\n",
    "ax.plot(x_smooth, y_pred, **linekwargs)\n",
    "rloc = (0.8*np.max(xlim), 0.9*np.max(ylim))\n",
    "ploc = (0.8*np.max(xlim), 0.83*np.max(ylim))\n",
    "nloc = (0.8*np.max(xlim), 0.76*np.max(ylim))\n",
    "sloc = (0.8*np.max(xlim), 0.69*np.max(ylim))\n",
    "ax.annotate(f'{r_sq_label}', xy=rloc)\n",
    "ax.annotate(f'p-value={np.round(p, 8)}', xy=ploc)\n",
    "ax.annotate(f'N={len(y)}', xy=nloc)\n",
    "ax.annotate(f'Slope={str(slope)[0:8]}', xy=sloc)\n",
    "plotting.format_ticks(ax, xminorspace=xminorspace)\n",
    "# ax.annotate(f'slope={np.round(slope, 3)}', xy=sloc)\n",
    "print(f'N={len(df.loc[:, yvar])}')\n",
    "fig.savefig(savepath)\n",
    "print(f'Saved figure at: \\n{savepath}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".byc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "9fb5b175484e3445d43235b3273539be3d3c237c7e7152a5ca180dad8b624fac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
